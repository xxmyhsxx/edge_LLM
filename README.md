### Edge-LMM-Optimizer âš¡

Edge-LMM-Optimizer æ˜¯ä¸€ä¸ªä¸“ä¸ºè¾¹ç¼˜è®¡ç®—è®¾å¤‡ï¼ˆç‰¹åˆ«æ˜¯ NVIDIA Jetson Orin NX 16GBï¼‰è®¾è®¡çš„å¤šæ¨¡æ€å¤§æ¨¡å‹ï¼ˆLMMï¼‰æ¨ç†ä¼˜åŒ–ä¸å®éªŒæ¡†æ¶ã€‚

æœ¬é¡¹ç›®æ—¨åœ¨è§£å†³å¤§å‚æ•°æ¨¡å‹ï¼ˆå¦‚ InterVL-8Bï¼‰åœ¨æ˜¾å­˜å—é™è®¾å¤‡ä¸Šçš„éƒ¨ç½²éš¾é¢˜ã€‚é€šè¿‡ åç«¯ (Backends)ã€ä¸šåŠ¡æµæ°´çº¿ (Pipelines) å’Œ ä¼˜åŒ–ç®—æ³• (Methods) çš„è§£è€¦è®¾è®¡ï¼Œå®ƒæ—¢èƒ½ä½œä¸ºé«˜æ•ˆçš„æ¨ç†å¼•æ“ï¼Œä¹Ÿèƒ½ä½œä¸ºç§‘ç ”ç®—æ³•ï¼ˆå¦‚å‰ªæã€é‡åŒ–ï¼‰çš„éªŒè¯å¹³å°ã€‚

#### ğŸŒŸ æ ¸å¿ƒç‰¹æ€§ (Key Features)

æè‡´æ˜¾å­˜é€‚é…: é’ˆå¯¹ Jetson 16GB ç»Ÿä¸€å†…å­˜æ¶æ„æ·±åº¦ä¼˜åŒ–ï¼Œé»˜è®¤é›†æˆé˜² OOM ç­–ç•¥ï¼ˆå¦‚åŠ¨æ€åˆ†è¾¨ç‡é™åˆ¶ã€Eager Modeï¼‰ã€‚

##### å¤šåç«¯æ”¯æŒ:

PyTorch: é€‚åˆç§‘ç ”ä¸ç®—æ³•éªŒè¯ï¼Œæ”¯æŒ Hook æ¨¡å‹å±‚ã€æ’å…¥å‰ªæ Maskã€‚

vLLM: (å¼€å‘ä¸­) é€‚åˆé«˜æ€§èƒ½ç”Ÿäº§éƒ¨ç½²ï¼Œæ”¯æŒ AWQ/GPTQ é‡åŒ–ã€‚

llama.cpp: (å¼€å‘ä¸­) æ”¯æŒ GGUF æ ¼å¼ï¼Œè¿›ä¸€æ­¥é™ä½æ˜¾å­˜éœ€æ±‚ã€‚

æµå¼æ¨ç† (Streaming): æ”¯æŒåƒ ChatGPT ä¸€æ ·çš„æ‰“å­—æœºæ•ˆæœï¼Œæå‡è¾¹ç¼˜ç«¯ç”¨æˆ·ä½“éªŒã€‚

ç®—æ³•éªŒè¯å¥—ä»¶: å†…ç½® Attention çƒ­åŠ›å›¾åˆ†æã€Token å‰ªæå¯è§†åŒ–å·¥å…·ã€‚

#### ğŸ“‚ é¡¹ç›®ç»“æ„æ¦‚è§ˆ (Project Structure)
â€˜â€™â€˜
Edge-LMM-Optimizer/
â”œâ”€â”€ assets/                 # æµ‹è¯•èµ„æºï¼ˆå›¾ç‰‡ã€Prompt æ¨¡æ¿ç­‰ï¼‰
â”œâ”€â”€ configs/                # é…ç½®æ–‡ä»¶ï¼ˆç¡¬ä»¶é™åˆ¶ã€æ¨ç†å‚æ•°ï¼‰
â”œâ”€â”€ src/                    # ã€æ ¸å¿ƒæºç ã€‘
â”‚   â”œâ”€â”€ backends/           # æ¨ç†å¼•æ“å°è£… (è´Ÿè´£åŠ è½½æ¨¡å‹ã€åº•å±‚æ¨ç†)
â”‚   â”‚   â”œâ”€â”€ base.py         # æ ‡å‡†æ¥å£å®šä¹‰
â”‚   â”‚   â”œâ”€â”€ torch_backend/  # PyTorch åç«¯å®ç°
â”‚   â”‚   â”œâ”€â”€ vllm_backend/   # vLLM åç«¯å®ç°
â”‚   â”‚   â””â”€â”€ lmdeploy_backend/ # LMDeploy åç«¯å®ç°
â”‚   â”‚
â”‚   â”œâ”€â”€ pipelines/          # ä¸šåŠ¡æµæ°´çº¿ (è´Ÿè´£é¢„å¤„ç†ã€Promptæ‹¼æ¥ã€æµå¼å°è£…)
â”‚   â”‚   â”œâ”€â”€ base_pipeline.py
â”‚   â”‚   â””â”€â”€ intervl_pipeline.py # InternVL ä¸“ç”¨æµæ°´çº¿
â”‚   â”‚
â”‚   â”œâ”€â”€ methods/            # ä¼˜åŒ–ç®—æ³•åº“ (ä½ çš„ç§‘ç ”æ ¸å¿ƒ)
â”‚   â”‚   â”œâ”€â”€ pruning/        # å‰ªæç®—æ³• (Token Pruning)
â”‚   â”‚   â””â”€â”€ quantization/   # é‡åŒ–è„šæœ¬
â”‚   â”‚
â”‚   â”œâ”€â”€ models/             # æ¨¡å‹é€‚é…å±‚ (å±è”½ä¸åŒæ¨¡å‹çš„ç»“æ„å·®å¼‚)
â”‚   â”‚   â””â”€â”€ base.py         # å®šä¹‰è·å– Attention å±‚çš„æ ‡å‡†æ¥å£
â”‚   â”‚
â”‚   â””â”€â”€ utils/              # é€šç”¨å·¥å…·
â”‚       â”œâ”€â”€ media_loader.py # ç»Ÿä¸€åª’ä½“åŠ è½½å™¨ (Image/Video -> PIL)
â”‚       â”œâ”€â”€ video.py        # è§†é¢‘æŠ½å¸§å·¥å…·
â”‚       â”œâ”€â”€ metrics.py      # æ˜¾å­˜ä¸TPSç›‘æ§
â”‚       â””â”€â”€ attention_analysis.py # æ³¨æ„åŠ›å¯è§†åŒ–å·¥å…·
â”‚
â”œâ”€â”€ test/                   # å•å…ƒæµ‹è¯•ä¸è°ƒè¯•è„šæœ¬ (Playground)
â”œâ”€â”€ benchmark.py            # è‡ªåŠ¨åŒ–è·‘åˆ†è„šæœ¬
â”œâ”€â”€ main.py                 # ç»Ÿä¸€ CLI å…¥å£
â””â”€â”€ requirements.txt        # é¡¹ç›®ä¾èµ–
â€™â€˜â€™

#### ğŸ§© æ ¸å¿ƒæ¨¡å—è¯¦è§£

##### 1. æ¨ç†åç«¯ (src/backends)

åç«¯åªè´Ÿè´£â€œæ€ä¹ˆè·‘â€ã€‚å®ƒåŠ è½½æ¨¡å‹æƒé‡ï¼Œæ¥æ”¶å¤„ç†å¥½çš„ Tensor æˆ– Promptï¼Œè¿”å›ç»“æœã€‚

PyTorchBackend: ç›®å‰çš„ä¸»åŠ›åç«¯ã€‚æ”¯æŒæµå¼è¾“å‡º (stream=True)ï¼Œå†…éƒ¨ä½¿ç”¨å¤šçº¿ç¨‹è¿è¡Œ model.chatã€‚

##### 2. ä¸šåŠ¡æµæ°´çº¿ (src/pipelines)

æµæ°´çº¿è´Ÿè´£â€œæ€ä¹ˆå¤„ç†æ•°æ®â€ã€‚

InternVLPipeline:

è‡ªåŠ¨åˆ¤æ–­è¾“å…¥æ˜¯å•å›¾ã€å¤šå›¾è¿˜æ˜¯è§†é¢‘ã€‚

é›†æˆ VideoProcessor è¿›è¡Œè§†é¢‘æŠ½å¸§ã€‚

æ‰§è¡Œ InternVL ç‰¹æœ‰çš„ dynamic_preprocess (åŠ¨æ€åˆ‡ç‰‡)ã€‚

æµå¼æ”¯æŒ: å½“ stream=True æ—¶ï¼Œè¿”å›ä¸€ä¸ª Python ç”Ÿæˆå™¨ (generator)ã€‚

##### 3. ä¼˜åŒ–ç®—æ³• (src/methods)

pruning/token_pruner.py: ç®¡ç†å‰ªæç”Ÿå‘½å‘¨æœŸã€‚

pruning/pruning_hook.py: å®é™…æ³¨å…¥æ¨¡å‹çš„ Hookï¼Œè´Ÿè´£åœ¨æ¨ç†æ—¶è®¡ç®— Token é‡è¦æ€§å¹¶ç”Ÿæˆ Maskã€‚

##### ğŸ› ï¸ å¿«é€Ÿä¸Šæ‰‹ (Quick Start)

1. ç¯å¢ƒå‡†å¤‡

ç¡®ä¿ JetPack ç¯å¢ƒå°±ç»ª (æ¨è JetPack 6.0+)ï¼Œå®‰è£…åŸºç¡€ä¾èµ–ï¼š

pip install -r requirements.txt
å¦‚æœä½¿ç”¨ vLLM æˆ– llama.cppï¼Œè¯·å‚è€ƒå„è‡ªçš„å®˜æ–¹æ–‡æ¡£è¿›è¡Œç¼–è¯‘å®‰è£…


2. è¿è¡ŒåŸºå‡†æµ‹è¯• (Benchmark)

æµ‹è¯•æ¨¡å‹åœ¨å½“å‰ç¡¬ä»¶ä¸Šçš„é€Ÿåº¦ (TPS) å’Œæ˜¾å­˜å ç”¨ã€‚

python benchmark.py --model_path /path/to/InternVL-Chat-V1-5


3. å¯åŠ¨æ¨ç† (CLI)

æ™®é€šå¯¹è¯ (æ–‡æœ¬/å›¾ç‰‡)

python main.py \
    --model_path /path/to/model \
    --prompt "Describe this image." \
    --image assets/dog.jpg


è§†é¢‘ç†è§£ (æµå¼è¾“å‡º)

# --stream å‚æ•°å¼€å¯æµå¼è¾“å‡º
python main.py \
    --model_path /path/to/model \
    --video assets/demo.mp4 \
    --prompt "What is happening in this video?" \
    --stream


ğŸ§ª å¼€å‘ä¸è°ƒè¯• (Development)

å¦‚ä½•æ·»åŠ æ–°çš„å‰ªæç®—æ³•ï¼Ÿ

åœ¨ src/methods/pruning/ ä¸‹æ–°å»ºç®—æ³•æ–‡ä»¶ã€‚

ç¼–å†™é€»è¾‘ï¼šæ¥æ”¶ Attention Mapï¼Œè®¡ç®— Scoreï¼Œç”Ÿæˆ Maskã€‚

åœ¨ test/debug_pruning.py ä¸­ä½¿ç”¨ä¼ªé€ æ•°æ®éªŒè¯æ•°å­¦é€»è¾‘ã€‚

å¦‚ä½•è¿›è¡Œæ³¨æ„åŠ›åˆ†æï¼Ÿ

æˆ‘ä»¬æä¾›äº†å¯è§†åŒ–çš„åˆ†æå·¥å…·ï¼Œå¯ä»¥ç”Ÿæˆçƒ­åŠ›å›¾å¹¶ä¿å­˜ã€‚

åœ¨ test/test_attention.py ä¸­
from src.utils.attention_analysis import AttentionAnalyzer

analyzer = AttentionAnalyzer(model, tokenizer)
è·å–æœ€åä¸€å±‚çš„æ³¨æ„åŠ›
attn_data = analyzer.get_attention_scores(inputs, layer_idx=-1)
ç»˜åˆ¶çƒ­åŠ›å›¾
analyzer.plot_heatmap(attn_data, save_path="heatmap.png")


ğŸ“ å¸¸è§é—®é¢˜ (FAQ)

Q: ä¸ºä»€ä¹ˆè§†é¢‘æ¨ç†æ˜¾å­˜å ç”¨å¾ˆé«˜ï¼Ÿ

A: InternVL é»˜è®¤ä¼šå¯¹æ¯ä¸€å¸§è¿›è¡ŒåŠ¨æ€åˆ‡ç‰‡ï¼ˆä¸€å¼ å›¾åˆ‡æˆ ~12 ä¸ª Patchï¼‰ã€‚å¯¹äºè§†é¢‘ï¼Œæˆ‘ä»¬åœ¨ InternVLPipeline ä¸­é»˜è®¤é™åˆ¶äº† max_num=1ï¼Œå³æ¯å¸§åªä½œä¸ºä¸€ä¸ª Patch å¤„ç†ï¼Œä»¥èŠ‚çœæ˜¾å­˜ã€‚

Q: æµå¼è¾“å‡ºå¡ä½ä¸åŠ¨ï¼Ÿ

A: è¯·æ£€æŸ¥ TextIteratorStreamer æ˜¯å¦æ­£ç¡®åˆå§‹åŒ–ï¼Œä»¥åŠ model.chat æ˜¯å¦åœ¨ç‹¬ç«‹çš„çº¿ç¨‹ä¸­è¿è¡Œã€‚å‚è€ƒ src/backends/torch_backend/internvl.py ä¸­çš„å®ç°ã€‚