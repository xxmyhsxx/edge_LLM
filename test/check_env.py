# tests/check_env.py
import torch
import sys
import os


def check_environment():
    print("=" * 30)
    print("ğŸ” ç¯å¢ƒä½“æ£€æŠ¥å‘Š")
    print("=" * 30)

    # 1. Python & PyTorch ç‰ˆæœ¬
    print(f"Python Version: {sys.version.split()[0]}")
    print(f"PyTorch Version: {torch.__version__}")

    # 2. CUDA æ£€æŸ¥
    if torch.cuda.is_available():
        print(f"CUDA Available: âœ… Yes")
        print(f"Device Name: {torch.cuda.get_device_name(0)}")
        print(f"CUDA Version: {torch.version.cuda}")

        # 3. æ˜¾å­˜æ£€æŸ¥ (å…³é”®!)
        total_mem = torch.cuda.get_device_properties(0).total_memory / (1024 ** 3)
        print(f"Total GPU Memory: {total_mem:.2f} GB")

        # å°è¯•åˆ†é…ä¸€ä¸ªå° Tensor æµ‹è¯•
        try:
            x = torch.ones(1).cuda()
            print("Tensor Allocation: âœ… Success")
        except Exception as e:
            print(f"Tensor Allocation: âŒ Failed ({e})")
    else:
        print("CUDA Available: âŒ No (ä½ åœ¨ç”¨ CPU è·‘å—?)")


if __name__ == "__main__":
    check_environment()